{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# LlamaParse Parsing Pipeline\n",
    "\n",
    "This notebook demonstrates the complete LlamaParse parsing pipeline for PDF documents, including:\n",
    "- Document parsing with LlamaIndex's advanced PDF processing\n",
    "- Markdown conversion and formatting\n",
    "- Performance timing and analysis\n",
    "- Comparison with other parsing methods\n",
    "\n",
    "## Setup and Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "import os\n",
    "from pathlib import Path\n",
    "import time\n",
    "import json\n",
    "from typing import Dict, Any\n",
    "\n",
    "# Add the src directory to Python path\n",
    "sys.path.append('../src')\n",
    "\n",
    "from simple_rag.parsers.parser_llama import LlamaParseProcessor\n",
    "from simple_rag.main_parser import MainParserProcessor"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Configuration\n",
    "\n",
    "Set up the input PDF file and output directory for processing."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Configuration\n",
    "PDF_FILE = \"../data/raw/test_p1_7.pdf\"  # Change this to your PDF file\n",
    "OUTPUT_DIR = Path(\"../data/processed\")\n",
    "OUTPUT_DIR.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "print(f\"üìÑ Input PDF: {PDF_FILE}\")\n",
    "print(f\"üìÅ Output directory: {OUTPUT_DIR}\")\n",
    "print(f\"‚úÖ PDF exists: {os.path.exists(PDF_FILE)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Environment Check\n",
    "\n",
    "Verify that the LLAMA_CLOUD_API_KEY is properly configured."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check for LlamaCloud API key\n",
    "api_key = os.getenv('LLAMA_CLOUD_API_KEY')\n",
    "if api_key:\n",
    "    print(f\"üîë LLAMA_CLOUD_API_KEY found: {api_key[:8]}...{api_key[-4:]}\")\n",
    "else:\n",
    "    print(\"‚ö†Ô∏è  LLAMA_CLOUD_API_KEY not found in environment variables\")\n",
    "    print(\"   Please set your API key: export LLAMA_CLOUD_API_KEY='your_key_here'\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Initialize LlamaParse Parser\n",
    "\n",
    "Create the LlamaParseProcessor instance with advanced parsing capabilities."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize the LlamaParse parser\n",
    "try:\n",
    "    parser = LlamaParseProcessor()\n",
    "    print(\"ü¶ô LlamaParse parser initialized successfully\")\n",
    "    print(f\"   API Key configured: {parser.api_key is not None}\")\n",
    "except Exception as e:\n",
    "    print(f\"‚ùå Failed to initialize LlamaParse parser: {e}\")\n",
    "    print(\"   Please check your LLAMA_CLOUD_API_KEY configuration\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Document Parsing\n",
    "\n",
    "Parse the PDF document using LlamaParse's advanced AI-powered extraction."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Start timing\n",
    "start_time = time.time()\n",
    "\n",
    "print(\"üöÄ Starting LlamaParse parsing...\")\n",
    "print(\"=\" * 50)\n",
    "print(\"‚è≥ This may take a few moments as LlamaParse processes the document...\")\n",
    "\n",
    "try:\n",
    "    # Parse the document\n",
    "    documents = parser.parse_document(PDF_FILE, verbose=True)\n",
    "    \n",
    "    parsing_time = time.time() - start_time\n",
    "    print(f\"\\n‚è±Ô∏è  LlamaParse parsing completed in {parsing_time:.2f} seconds\")\n",
    "    print(f\"üìä Documents extracted: {len(documents)}\")\n",
    "    \n",
    "    # Show document info\n",
    "    for i, doc in enumerate(documents):\n",
    "        content_length = len(doc.text) if hasattr(doc, 'text') else 0\n",
    "        print(f\"   Document {i+1}: {content_length} characters\")\n",
    "        \n",
    "except Exception as e:\n",
    "    print(f\"‚ùå LlamaParse parsing failed: {e}\")\n",
    "    documents = []"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Markdown Conversion\n",
    "\n",
    "Convert the parsed content to well-formatted Markdown."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if documents:\n",
    "    print(\"\\nüìù Converting to Markdown format...\")\n",
    "    print(\"=\" * 35)\n",
    "    \n",
    "    # Convert to markdown\n",
    "    markdown_content = parser.convert_to_markdown(documents, verbose=True)\n",
    "    \n",
    "    print(f\"\\nüìÑ Markdown conversion completed\")\n",
    "    print(f\"üìä Total markdown length: {len(markdown_content)} characters\")\n",
    "    \n",
    "    # Show a preview of the markdown\n",
    "    preview_length = 500\n",
    "    print(f\"\\nüìñ Markdown Preview (first {preview_length} chars):\")\n",
    "    print(\"-\" * 50)\n",
    "    print(markdown_content[:preview_length])\n",
    "    if len(markdown_content) > preview_length:\n",
    "        print(\"...\")\n",
    "else:\n",
    "    print(\"‚ö†Ô∏è  No documents to convert - skipping markdown conversion\")\n",
    "    markdown_content = \"\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Content Analysis\n",
    "\n",
    "Analyze the structure and content of the parsed markdown."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if markdown_content:\n",
    "    print(\"\\nüìã Content Structure Analysis:\")\n",
    "    print(\"=\" * 35)\n",
    "    \n",
    "    # Count different markdown elements\n",
    "    lines = markdown_content.split('\\n')\n",
    "    \n",
    "    headers = [line for line in lines if line.strip().startswith('#')]\n",
    "    paragraphs = [line for line in lines if line.strip() and not line.strip().startswith('#') and not line.strip().startswith('|')]\n",
    "    tables = [line for line in lines if '|' in line]\n",
    "    \n",
    "    print(f\"üìä Structure Summary:\")\n",
    "    print(f\"   Total lines: {len(lines)}\")\n",
    "    print(f\"   Headers: {len(headers)}\")\n",
    "    print(f\"   Content paragraphs: {len(paragraphs)}\")\n",
    "    print(f\"   Table lines: {len(tables)}\")\n",
    "    \n",
    "    # Show headers structure\n",
    "    if headers:\n",
    "        print(f\"\\nüìë Document Structure (Headers):\")\n",
    "        for header in headers[:10]:  # Show first 10 headers\n",
    "            level = len(header) - len(header.lstrip('#'))\n",
    "            title = header.strip('#').strip()\n",
    "            indent = \"  \" * (level - 1)\n",
    "            print(f\"   {indent}{'#' * level} {title}\")\n",
    "        if len(headers) > 10:\n",
    "            print(f\"   ... and {len(headers) - 10} more headers\")\n",
    "else:\n",
    "    print(\"‚ö†Ô∏è  No markdown content to analyze\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Save Results\n",
    "\n",
    "Save the processed markdown content to a file for further use."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if markdown_content:\n",
    "    # Save markdown results\n",
    "    output_filename = f\"{Path(PDF_FILE).stem}_llamaparse_notebook.md\"\n",
    "    output_path = OUTPUT_DIR / output_filename\n",
    "    \n",
    "    with open(output_path, 'w', encoding='utf-8') as f:\n",
    "        f.write(markdown_content)\n",
    "    \n",
    "    print(f\"\\nüíæ Markdown saved to: {output_path}\")\n",
    "    print(f\"üìÅ File size: {output_path.stat().st_size / 1024:.1f} KB\")\n",
    "    \n",
    "    # Also save metadata as JSON\n",
    "    metadata = {\n",
    "        \"source_file\": PDF_FILE,\n",
    "        \"parser\": \"LlamaParse\",\n",
    "        \"processing_time\": parsing_time,\n",
    "        \"document_count\": len(documents),\n",
    "        \"markdown_length\": len(markdown_content),\n",
    "        \"timestamp\": time.strftime(\"%Y-%m-%d %H:%M:%S\")\n",
    "    }\n",
    "    \n",
    "    metadata_path = OUTPUT_DIR / f\"{Path(PDF_FILE).stem}_llamaparse_notebook_metadata.json\"\n",
    "    with open(metadata_path, 'w', encoding='utf-8') as f:\n",
    "        json.dump(metadata, f, indent=2)\n",
    "    \n",
    "    print(f\"üìã Metadata saved to: {metadata_path}\")\n",
    "else:\n",
    "    print(\"‚ö†Ô∏è  No content to save\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Performance Analysis\n",
    "\n",
    "Analyze the performance characteristics of the LlamaParse parsing pipeline."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if documents:\n",
    "    total_time = time.time() - start_time\n",
    "    \n",
    "    print(\"\\n‚ö° PERFORMANCE ANALYSIS\")\n",
    "    print(\"=\" * 30)\n",
    "    \n",
    "    file_size_mb = os.path.getsize(PDF_FILE) / (1024 * 1024)\n",
    "    chars_per_second = len(markdown_content) / total_time if total_time > 0 else 0\n",
    "    mb_per_second = file_size_mb / total_time if total_time > 0 else 0\n",
    "    \n",
    "    print(f\"üìÑ Input file size: {file_size_mb:.2f} MB\")\n",
    "    print(f\"‚è±Ô∏è  Total processing time: {total_time:.2f} seconds\")\n",
    "    print(f\"‚ö° Processing speed: {chars_per_second:.0f} chars/second\")\n",
    "    print(f\"‚ö° Throughput: {mb_per_second:.2f} MB/second\")\n",
    "    \n",
    "    # Quality metrics\n",
    "    if markdown_content:\n",
    "        output_size_mb = len(markdown_content.encode('utf-8')) / (1024 * 1024)\n",
    "        compression_ratio = file_size_mb / output_size_mb if output_size_mb > 0 else 0\n",
    "        print(f\"üíæ Output size: {output_size_mb:.2f} MB\")\n",
    "        print(f\"üìâ Compression ratio: {compression_ratio:.1f}x\")\n",
    "        \n",
    "        # Content density\n",
    "        words = len(markdown_content.split())\n",
    "        print(f\"üìù Word count: {words:,}\")\n",
    "        print(f\"üìä Words per MB: {words/file_size_mb:.0f}\")\n",
    "else:\n",
    "    print(\"‚ö†Ô∏è  No performance data available due to parsing failure\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Results Summary\n",
    "\n",
    "Display comprehensive results from the LlamaParse parsing pipeline."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"\\nüìä FINAL RESULTS SUMMARY\")\n",
    "print(\"=\" * 50)\n",
    "\n",
    "if documents:\n",
    "    print(f\"üìÑ Document: {os.path.basename(PDF_FILE)}\")\n",
    "    print(f\"ü¶ô Parser: LlamaParse (AI-powered)\")\n",
    "    print(f\"‚è±Ô∏è  Total Processing Time: {total_time:.2f} seconds\")\n",
    "    print(f\"‚úÖ Status: Successfully processed\")\n",
    "    print()\n",
    "    print(f\"üìã Content Summary:\")\n",
    "    print(f\"   - Documents extracted: {len(documents)}\")\n",
    "    print(f\"   - Markdown length: {len(markdown_content):,} characters\")\n",
    "    print(f\"   - Word count: {len(markdown_content.split()):,} words\")\n",
    "    \n",
    "    if headers:\n",
    "        print(f\"   - Headers found: {len(headers)}\")\n",
    "    if tables:\n",
    "        print(f\"   - Table lines: {len(tables)}\")\n",
    "    \n",
    "    print(f\"\\nüíæ Output Files:\")\n",
    "    if 'output_path' in locals():\n",
    "        print(f\"   - Markdown: {output_path}\")\n",
    "    if 'metadata_path' in locals():\n",
    "        print(f\"   - Metadata: {metadata_path}\")\n",
    "else:\n",
    "    print(f\"üìÑ Document: {os.path.basename(PDF_FILE)}\")\n",
    "    print(f\"ü¶ô Parser: LlamaParse (AI-powered)\")\n",
    "    print(f\"‚ùå Status: Processing failed\")\n",
    "    print(f\"‚ö†Ô∏è  Please check your API key configuration\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Comparison Notes\n",
    "\n",
    "### LlamaParse vs Unstructured Parsing\n",
    "\n",
    "**LlamaParse Advantages:**\n",
    "- AI-powered understanding of document structure\n",
    "- Better handling of complex layouts and tables\n",
    "- Clean markdown output with proper formatting\n",
    "- Excellent for documents with complex visual elements\n",
    "\n",
    "**LlamaParse Considerations:**\n",
    "- Requires API key and internet connection\n",
    "- Processing time depends on cloud service\n",
    "- Usage may be subject to rate limits and costs\n",
    "- Less granular control over individual elements\n",
    "\n",
    "**Best Use Cases:**\n",
    "- Research papers with complex formatting\n",
    "- Technical documents with tables and figures\n",
    "- Documents where structure preservation is critical\n",
    "- When high-quality markdown output is needed"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Conclusion\n",
    "\n",
    "The LlamaParse parsing pipeline provides AI-powered document understanding with:\n",
    "\n",
    "- **Advanced structure recognition** for complex documents\n",
    "- **Clean markdown output** with proper formatting\n",
    "- **Comprehensive performance metrics** and timing analysis\n",
    "- **Cloud-based processing** with state-of-the-art AI models\n",
    "\n",
    "The processed markdown is ready for further chunking, embedding, and integration into your RAG system."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
